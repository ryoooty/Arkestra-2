junior:
  provider: transformers
  model_id: Qwen/Qwen2.5-1.5B-Instruct
  load_in_4bit: true
  device_map: auto
  torch_dtype: float16
  use_chat_template: true
  max_new_tokens: 160
  temperature: 0.2
  stop: ["</json>"]
senior:
  provider: "transformers"
  model_path: "C:\\Users\\kosha\\models\\mistral-7b-instruct-v0_3"
  temperature: 0.7
  max_new_tokens: 512
  stop: ["</json>"]
